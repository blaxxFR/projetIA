{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DE DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#VISUALISATION ET IMPORT DE DONNEES\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "#SKLEARN FUNCTIONS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "\n",
    "########################      PRE-PROCESSING      #############################\n",
    "\n",
    "\n",
    "#ouverture et lecture des deux fichiers csv : frequences propres et entrées \n",
    "freq = pd.read_csv(open(\"testPOC.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "inputs = pd.read_csv(open(\"dictPOC.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "#2 dataFrames sont créés\n",
    "\n",
    "#keep 1 column of freq\n",
    "\n",
    "\n",
    "#Concatenation des deux dataframes dans le même DataFrame : data\n",
    "datas = [inputs, freq]\n",
    "datas = pd.concat(datas, axis=1)\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(data):\n",
    "    corr = data.corr()\n",
    "    sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "    plt.show()\n",
    "    print(corr)\n",
    "\n",
    "# plot_correlation_matrix(pd.DataFrame(datas))\n",
    "\n",
    "# d'apres la matrice de correlation, certaines entrées sont étroitement liées\n",
    "# on va donc supprimer certaines de ces valeurs pour conserver :\n",
    "# hauteur h, base b, la masse volumique rho, la longueur de la poutre L_tot\n",
    "to_drop = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8']\n",
    "datas = datas.drop(columns=to_drop)\n",
    "#keep 10000 random values of datas\n",
    "\n",
    "\n",
    "print(datas)\n",
    "######################      FIN PRE-PROCESSING      ###########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################      TRAIN_TEST_SPLIT      ############################\n",
    "# 70% de la population sera allouée à l'apprentissage, 30 % pour le test\n",
    "population_train = 0.7\n",
    "\n",
    "# mélange et séparation de nos données en 2 datasets  \n",
    "split_train, split_test = train_test_split(datas, train_size=population_train)\n",
    "\n",
    "# On extrait les données qui serviront d'objectif à atteindre, soit ici les \n",
    "# 8 fréquences propres à prédire\n",
    "\n",
    "entrees = ['L_tot','rho', 'h', 'b']\n",
    "split_target_train = split_train.drop(columns=entrees)\n",
    "split_target_test = split_test.drop(columns=entrees)\n",
    "\n",
    "\n",
    "frequences = [\"freq1\"]\n",
    "split_train = split_train.drop(columns=frequences)\n",
    "split_test = split_test.drop(columns=frequences)\n",
    "\n",
    "print(\"entrées train : \\n\",split_train)\n",
    "print(\"target train : \\n\", split_target_train)\n",
    "\n",
    "#split_train = entrees servant à entrainer le modèle\n",
    "#split test = entrees servant à tester le modèle\n",
    "#split_target_train = sorties d'entrainement du modèle\n",
    "#split_target_test = sorties de test du modèle \n",
    "\n",
    "\n",
    "#######################      FIN TR_TST_SPLIT      ############################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROCESSING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"my_grid_poly ={'polynomialfeatures__degree': [9],\n",
    "                'linearregression__fit_intercept': [True, False],\n",
    "                'linearregression__normalize': [True, False]}\n",
    "\n",
    "\n",
    "poly_reg_model = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "grid_search = GridSearchCV(poly_reg_model, my_grid_poly, cv=5, n_jobs=-1, verbose=2,)\n",
    "#print best score and model\n",
    "# Ravel plit_target_train\n",
    "jesuisunfdp = grid_search.fit(split_train, split_target_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poly_reg_model = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_model.fit(split_train, split_target_train)\n",
    "print(\"\",poly_reg_model.score(split_test, split_target_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred = poly_reg_model.predict(split_test)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred)[:80])\n",
    "plt.plot((np.array(split_target_test)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "polynomial_features = PolynomialFeatures(degree=9)\n",
    "linear_regression = LinearRegression(fit_intercept=True, normalize=True)\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"polynomial_features\", polynomial_features),\n",
    "        (\"linear_regression\", linear_regression),\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(split_train, split_target_train)\n",
    "print(\"\",pipeline.score(split_test, split_target_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poly_reg_model = PolynomialRegression(2 , fit_intercept=True, normalize=True)\n",
    "poly_reg_model.fit(split_train, split_target_train)\n",
    "print(\"\",poly_reg_model.score(split_test, split_target_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PASSAGE A L'EVALUATION DU MODELE EN FONCTION DU NOMBRE DE DONNEES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freq = pd.read_csv(open(\"test10el.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "inputs = pd.read_csv(open(\"dict10el.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "#2 dataFrames sont créés\n",
    "\n",
    "#keep 1 column of freq\n",
    "\n",
    "\n",
    "#Concatenation des deux dataframes dans le même DataFrame : data\n",
    "datas = [inputs, freq]\n",
    "datas = pd.concat(datas, axis=1)\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(data):\n",
    "    corr = data.corr()\n",
    "    sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "    plt.show()\n",
    "    print(corr)\n",
    "\n",
    "# plot_correlation_matrix(pd.DataFrame(datas))\n",
    "\n",
    "# d'apres la matrice de correlation, certaines entrées sont étroitement liées\n",
    "# on va donc supprimer certaines de ces valeurs pour conserver :\n",
    "# hauteur h, base b, la masse volumique rho, la longueur de la poutre L_tot\n",
    "to_drop = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8']\n",
    "datas = datas.drop(columns=to_drop)\n",
    "#keep 10000 random values of datas\n",
    "\n",
    "\n",
    "print(datas)\n",
    "######################      FIN PRE-PROCESSING      ###########################\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# keep 10000 random values of datas\n",
    "import time\n",
    "\n",
    "\n",
    "score = []\n",
    "nbr_values = []\n",
    "exec_time = []\n",
    "\n",
    "for i in range(1500,3500,100):\n",
    "\n",
    "    new_datas = datas.sample(i)\n",
    "    #######################      TRAIN_TEST_SPLIT      ############################\n",
    "    # 70% de la population sera allouée à l'apprentissage, 30 % pour le test\n",
    "    population_train = 0.7\n",
    "\n",
    "    # mélange et séparation de nos données en 2 datasets  \n",
    "    split_train, split_test = train_test_split(new_datas, train_size=population_train)\n",
    "\n",
    "    # On extrait les données qui serviront d'objectif à atteindre, soit ici les \n",
    "    # 8 fréquences propres à prédire\n",
    "\n",
    "    entrees = ['L_tot','rho', 'h', 'b']\n",
    "    split_target_train = split_train.drop(columns=entrees)\n",
    "    split_target_test = split_test.drop(columns=entrees)\n",
    "\n",
    "\n",
    "    frequences = [\"freq1\"]\n",
    "    split_train = split_train.drop(columns=frequences)\n",
    "    split_test = split_test.drop(columns=frequences)\n",
    "    start = time.time()\n",
    "    poly_reg_model = PolynomialRegression(9 , fit_intercept=True, normalize=True)\n",
    "    poly_reg_model.fit(split_train, split_target_train)\n",
    "    end = (time.time() - start)\n",
    "    score.append(poly_reg_model.score(split_test, split_target_test))\n",
    "    nbr_values.append(i)\n",
    "    exec_time.append(time.time() - start)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(nbr_values, score)\n",
    "plt.plot(nbr_values, exec_time)\n",
    "plt.legend(\n",
    "    ['score', 'exec_time'])\n",
    "plt.show()\n",
    "\n",
    "print(score)\n",
    "print(exec_time)\n",
    "print(nbr_values)\n",
    "\n",
    "Y_pred = poly_reg_model.predict(split_test)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred)[:80])\n",
    "plt.plot((np.array(split_target_test)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "# show best ratio score / exec_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrainement 100 elements finnis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freq = pd.read_csv(open(\"test100.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "inputs = pd.read_csv(open(\"dict100.csv\", \"r\"),\n",
    "                    delimiter=\",\")\n",
    "\n",
    "# delete last column of inputs\n",
    "#2 dataFrames sont créés\n",
    "\n",
    "#keep 1 column of freq\n",
    "\n",
    "\n",
    "#Concatenation des deux dataframes dans le même DataFrame : data\n",
    "datas = [inputs, freq]\n",
    "datas = pd.concat(datas, axis=1)\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(data):\n",
    "    corr = data.corr()\n",
    "    sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "    plt.show()\n",
    "    print(corr)\n",
    "\n",
    "# plot_correlation_matrix(pd.DataFrame(datas))\n",
    "\n",
    "# d'apres la matrice de correlation, certaines entrées sont étroitement liées\n",
    "# on va donc supprimer certaines de ces valeurs pour conserver :\n",
    "# hauteur h, base b, la masse volumique rho, la longueur de la poutre L_tot\n",
    "to_drop = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8','Mat']\n",
    "datas = datas.drop(columns=to_drop)\n",
    "#keep 10000 random values of datas\n",
    "\n",
    "\n",
    "print(datas)\n",
    "######################      FIN PRE-PROCESSING      ###########################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "score = []\n",
    "nbr_values = []\n",
    "exec_time = []\n",
    "\n",
    "for i in range(2500,5000,100):\n",
    "\n",
    "    new_datas = datas.sample(i)\n",
    "    #######################      TRAIN_TEST_SPLIT      ############################\n",
    "    # 70% de la population sera allouée à l'apprentissage, 30 % pour le test\n",
    "    population_train = 0.7\n",
    "\n",
    "    # mélange et séparation de nos données en 2 datasets  \n",
    "    split_train, split_test = train_test_split(new_datas, train_size=population_train)\n",
    "\n",
    "    # On extrait les données qui serviront d'objectif à atteindre, soit ici les \n",
    "    # 8 fréquences propres à prédire\n",
    "\n",
    "    entrees = ['L_tot','rho', 'h', 'b']\n",
    "    split_target_train = split_train.drop(columns=entrees)\n",
    "    split_target_test = split_test.drop(columns=entrees)\n",
    "\n",
    "\n",
    "    frequences = [\"freq1\"]\n",
    "    split_train = split_train.drop(columns=frequences)\n",
    "    split_test = split_test.drop(columns=frequences)\n",
    "    start = time.time()\n",
    "    poly_reg_model = PolynomialRegression(9 , fit_intercept=True, normalize=True)\n",
    "    poly_reg_model.fit(split_train, split_target_train)\n",
    "    end = (time.time() - start)\n",
    "    score.append(poly_reg_model.score(split_test, split_target_test))\n",
    "    nbr_values.append(i)\n",
    "    exec_time.append(time.time() - start)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(nbr_values, score)\n",
    "plt.plot(nbr_values, exec_time)\n",
    "plt.legend(\n",
    "    ['score', 'exec_time'])\n",
    "plt.show()\n",
    "\n",
    "print(score)\n",
    "print(exec_time)\n",
    "print(nbr_values)\n",
    "\n",
    "Y_pred = poly_reg_model.predict(split_test)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred)[:80])\n",
    "plt.plot((np.array(split_target_test)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "for i in range(0, len(score)):\n",
    "    score[i] = score[i] / exec_time[i]\n",
    "  \n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(nbr_values, score)\n",
    "plt.legend(\n",
    "    ['score / exec_time'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrainement des modèles pour les autres formes de poutres\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load et gestion des données"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "freq_cercle = pd.read_csv(open(\"gen_data/test_Cercle.csv\", \"r\"),delimiter=\",\")\n",
    "input_cercle = pd.read_csv(open(\"gen_data/dict_Cercle.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_cercle_creux = pd.read_csv(open(\"gen_data/test_Cercle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "input_cercle_creux = pd.read_csv(open(\"gen_data/dict_Cercle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle_creux = pd.read_csv(open(\"gen_data/test_Rectangle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle_creux = pd.read_csv(open(\"gen_data/dict_Rectangle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle = pd.read_csv(open(\"test10el.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle = pd.read_csv(open(\"dict10el.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle100el = pd.read_csv(open(\"test100.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle100el = pd.read_csv(open(\"dict100.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "data_cercle = [input_cercle, freq_cercle]\n",
    "data_cercle = pd.concat(data_cercle, axis=1)\n",
    "\n",
    "data_cercle_creux = [input_cercle_creux, freq_cercle_creux]\n",
    "data_cercle_creux = pd.concat(data_cercle_creux, axis=1)\n",
    "\n",
    "data_rectangle_creux = [input_rectangle_creux, freq_rectangle_creux]\n",
    "data_rectangle_creux = pd.concat(data_rectangle_creux, axis=1)\n",
    "\n",
    "data_rectangle = [input_rectangle, freq_rectangle]\n",
    "data_rectangle = pd.concat(data_rectangle, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "to_drop = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8','Mat']\n",
    "to_drop_sans_mat = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8']\n",
    "freq1 = frequences\n",
    "\n",
    "data_cercle = data_cercle.drop(columns=to_drop)\n",
    "data_cercle_creux = data_cercle_creux.drop(columns=to_drop)\n",
    "data_rectangle_creux = data_rectangle_creux.drop(columns=to_drop)\n",
    "data_rectangle = data_rectangle.drop(columns=to_drop_sans_mat)\n",
    "\n",
    "\n",
    "split_train_cercle,split_test_cercle = train_test_split(data_cercle, train_size=population_train)\n",
    "entrees_cercle = ['L_tot','rho', 'r']\n",
    "split_target_train_cercle = split_train_cercle.drop(columns=entrees_cercle)\n",
    "split_target_test_cercle = split_test_cercle.drop(columns=entrees_cercle)\n",
    "split_train_cercle.head(10)\n",
    "print(split_train_cercle)\n",
    "\n",
    "\n",
    "\n",
    "split_train_cercle_creux,split_test_cercle_creux = train_test_split(data_cercle_creux, train_size=population_train)\n",
    "entrees_cercle_creux = ['L_tot','rho', 'r_ext','r_int']\n",
    "split_target_train_cercle_creux = split_train_cercle_creux.drop(columns=entrees_cercle_creux)\n",
    "split_target_test_cercle_creux = split_test_cercle_creux.drop(columns=entrees_cercle_creux)\n",
    "split_train_cercle_creux = split_train_cercle_creux.drop(columns=freq1)\n",
    "split_test_cercle_creux = split_test_cercle_creux.drop(columns=freq1)\n",
    "\n",
    "\n",
    "entrees_rectangle_creux = ['L_tot','rho', 'h_ext','b_ext','h_int','b_int']\n",
    "split_train_rectangle_creux,split_test_rectangle_creux = train_test_split(data_rectangle_creux, train_size=population_train)\n",
    "split_target_train_rectangle_creux = split_train_rectangle_creux.drop(columns=entrees_rectangle_creux)\n",
    "split_target_test_rectangle_creux = split_test_rectangle_creux.drop(columns=entrees_rectangle_creux)\n",
    "split_train_rectangle_creux = split_train_rectangle_creux.drop(columns=freq1)\n",
    "split_test_rectangle_creux = split_test_rectangle_creux.drop(columns=freq1)\n",
    "\n",
    "\n",
    "entrees_rectangle = ['L_tot','rho', 'h','b']\n",
    "split_train_rectangle,split_test_rectangle = train_test_split(data_rectangle, train_size=population_train)\n",
    "split_target_train_rectangle = split_train_rectangle.drop(columns=entrees_rectangle)\n",
    "split_target_test_rectangle = split_test_rectangle.drop(columns=entrees_rectangle)\n",
    "split_train_rectangle = split_train_rectangle.drop(columns=freq1)\n",
    "split_test_rectangle = split_test_rectangle.drop(columns=freq1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrainement des modèles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "poly_reg_cercle = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_cercle.fit(split_train_cercle, split_target_train_cercle)\n",
    "poly_reg_cercle_creux = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_cercle_creux.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "poly_reg_rectangle_creux = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_rectangle_creux.fit(split_train_rectangle_creux, split_target_train_rectangle_creux)\n",
    "poly_reg_rectangle = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_rectangle.fit(split_train_rectangle, split_target_train_rectangle)\n",
    "\n",
    "Y_pred_cercle = poly_reg_cercle.predict(split_test_cercle)\n",
    "Y_pred_cercle_creux = poly_reg_cercle_creux.predict(split_test_cercle_creux)\n",
    "Y_pred_rectangle_creux = poly_reg_rectangle_creux.predict(split_test_rectangle_creux)\n",
    "Y_pred_rectangle = poly_reg_rectangle.predict(split_test_rectangle)\n",
    "\n",
    "# print score for each modèle\n",
    "print(\"Cercle : \",poly_reg_cercle.score(split_test_cercle, split_target_test_cercle))\n",
    "print(\"Cercle creux\",poly_reg_cercle_creux.score(split_test_cercle_creux, split_target_test_cercle_creux))\n",
    "print(\"Rectangle creuc\",poly_reg_rectangle_creux.score(split_test_rectangle_creux, split_target_test_rectangle_creux))\n",
    "print(\"Rectangle\",poly_reg_rectangle.score(split_test_rectangle, split_target_test_rectangle))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "split_train_rectangle.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grid search for cercle_creux\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "\"\"\"my_grid_poly ={'polynomialfeatures__degree': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                'linearregression__fit_intercept': [True],\n",
    "                'linearregression__normalize': [True]}\n",
    "grid = GridSearchCV(PolynomialRegression(), my_grid_poly, cv=2,verbose=1)\n",
    "grid.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\"\"\"\n",
    "# best param degré = 6 true true for 0.97 best score \n",
    "\n",
    "my_grid_rf ={'n_estimators': [80],\n",
    "                'max_depth': [19,],\n",
    "                'min_samples_split': [2,3,4,5,6,7,8,9,10],\n",
    "              }\n",
    "                \n",
    "grid = GridSearchCV(RandomForestRegressor(), my_grid_rf, cv=2,verbose=1)\n",
    "grid.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gen_model_Rectangle_creux' from 'other_freqs' (C:\\Dev\\5A\\apprentissage_automatique\\projetIA\\other_freqs.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_8328\\3059997627.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m plt.show()\"\"\"\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mother_freqs\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mgen_model_Rectangle_creux\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgen_model_Cercle_creux\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgen_model_cercle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgen_model_rect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[0mreg_lin_rect\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_model_rect\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'gen_model_Rectangle_creux' from 'other_freqs' (C:\\Dev\\5A\\apprentissage_automatique\\projetIA\\other_freqs.py)"
     ]
    }
   ],
   "source": [
    "\"\"\"# plot prediction\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_cercle)[:80])\n",
    "plt.plot((np.array(split_target_test_cercle)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_cercle_creux)[:80])\n",
    "plt.plot((np.array(split_target_test_cercle_creux)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_rectangle_creux)[:80])\n",
    "plt.plot((np.array(split_target_test_rectangle_creux)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\"\"\"\n",
    "\n",
    "from other_freqs import gen_model_Rectangle_creux, gen_model_Cercle_creux, gen_model_cercle, gen_model_rect\n",
    "\n",
    "reg_lin_rect = gen_model_rect()\n",
    "reg_lin_cercle = gen_model_cercle()\n",
    "reg_lin_rect_creux = gen_model_Rectangle_creux()\n",
    "reg_lin_cercle_creux = gen_model_Cercle_creux()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save all 4 models with pickle\n",
    "with open('model_cercle.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_cercle, f)\n",
    "with open('model_cercle_creux.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_cercle_creux, f)\n",
    "with open('model_rectangle_creux.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_rectangle_creux, f)\n",
    "with open('model_rectangle.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_rectangle, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement des modèles pour les autres formes de poutres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load et gestion des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         L_tot   rho         r        freq1\n",
      "449   0.514264  8900  0.044380   175.255997\n",
      "1373  0.577621  4510  0.027447   115.722000\n",
      "962   0.153427  2700  0.004409   264.896088\n",
      "960   0.912649  8900  0.016348    20.498699\n",
      "2132  0.646620  8900  0.031607    78.946899\n",
      "...        ...   ...       ...          ...\n",
      "258   0.906701  2700  0.076221   131.139099\n",
      "1561  0.512010  2500  0.037824   212.083099\n",
      "233   0.128880  7850  0.012527  1091.419800\n",
      "272   0.491170  8900  0.041239   178.527893\n",
      "415   0.330031  8900  0.010597   101.608597\n",
      "\n",
      "[1750 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "freq_cercle = pd.read_csv(open(\"gen_data/test_Cercle.csv\", \"r\"),delimiter=\",\")\n",
    "input_cercle = pd.read_csv(open(\"gen_data/dict_Cercle.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_cercle_creux = pd.read_csv(open(\"gen_data/test_Cercle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "input_cercle_creux = pd.read_csv(open(\"gen_data/dict_Cercle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle_creux = pd.read_csv(open(\"gen_data/test_Rectangle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle_creux = pd.read_csv(open(\"gen_data/dict_Rectangle_Creux.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle = pd.read_csv(open(\"test10el.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle = pd.read_csv(open(\"dict10el.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "freq_rectangle100el = pd.read_csv(open(\"test100.csv\", \"r\"),delimiter=\",\")\n",
    "input_rectangle100el = pd.read_csv(open(\"dict100.csv\", \"r\"),delimiter=\",\")\n",
    "\n",
    "data_cercle = [input_cercle, freq_cercle]\n",
    "data_cercle = pd.concat(data_cercle, axis=1)\n",
    "\n",
    "data_cercle_creux = [input_cercle_creux, freq_cercle_creux]\n",
    "data_cercle_creux = pd.concat(data_cercle_creux, axis=1)\n",
    "\n",
    "data_rectangle_creux = [input_rectangle_creux, freq_rectangle_creux]\n",
    "data_rectangle_creux = pd.concat(data_rectangle_creux, axis=1)\n",
    "\n",
    "data_rectangle = [input_rectangle, freq_rectangle]\n",
    "data_rectangle = pd.concat(data_rectangle, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "to_drop = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8','Mat']\n",
    "to_drop_sans_mat = ['NbElts', 'S', 'I', 'L', 'E','freq2','freq3','freq4','freq5','freq6','freq7','freq8']\n",
    "freq1 = frequences\n",
    "\n",
    "data_cercle = data_cercle.drop(columns=to_drop)\n",
    "data_cercle_creux = data_cercle_creux.drop(columns=to_drop)\n",
    "data_rectangle_creux = data_rectangle_creux.drop(columns=to_drop)\n",
    "data_rectangle = data_rectangle.drop(columns=to_drop_sans_mat)\n",
    "\n",
    "\n",
    "split_train_cercle,split_test_cercle = train_test_split(data_cercle, train_size=population_train)\n",
    "entrees_cercle = ['L_tot','rho', 'r']\n",
    "split_target_train_cercle = split_train_cercle.drop(columns=entrees_cercle)\n",
    "split_target_test_cercle = split_test_cercle.drop(columns=entrees_cercle)\n",
    "split_train_cercle.head(10)\n",
    "print(split_train_cercle)\n",
    "\n",
    "\n",
    "\n",
    "split_train_cercle_creux,split_test_cercle_creux = train_test_split(data_cercle_creux, train_size=population_train)\n",
    "entrees_cercle_creux = ['L_tot','rho', 'r_ext','r_int']\n",
    "split_target_train_cercle_creux = split_train_cercle_creux.drop(columns=entrees_cercle_creux)\n",
    "split_target_test_cercle_creux = split_test_cercle_creux.drop(columns=entrees_cercle_creux)\n",
    "split_train_cercle_creux = split_train_cercle_creux.drop(columns=freq1)\n",
    "split_test_cercle_creux = split_test_cercle_creux.drop(columns=freq1)\n",
    "\n",
    "\n",
    "entrees_rectangle_creux = ['L_tot','rho', 'h_ext','b_ext','h_int','b_int']\n",
    "split_train_rectangle_creux,split_test_rectangle_creux = train_test_split(data_rectangle_creux, train_size=population_train)\n",
    "split_target_train_rectangle_creux = split_train_rectangle_creux.drop(columns=entrees_rectangle_creux)\n",
    "split_target_test_rectangle_creux = split_test_rectangle_creux.drop(columns=entrees_rectangle_creux)\n",
    "split_train_rectangle_creux = split_train_rectangle_creux.drop(columns=freq1)\n",
    "split_test_rectangle_creux = split_test_rectangle_creux.drop(columns=freq1)\n",
    "\n",
    "\n",
    "entrees_rectangle = ['L_tot','rho', 'h','b']\n",
    "split_train_rectangle,split_test_rectangle = train_test_split(data_rectangle, train_size=population_train)\n",
    "split_target_train_rectangle = split_train_rectangle.drop(columns=entrees_rectangle)\n",
    "split_target_test_rectangle = split_test_rectangle.drop(columns=entrees_rectangle)\n",
    "split_train_rectangle = split_train_rectangle.drop(columns=freq1)\n",
    "split_test_rectangle = split_test_rectangle.drop(columns=freq1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cercle :  1.0\n",
      "Cercle creux 0.6955744977851921\n",
      "Rectangle creuc -6055818.442892607\n",
      "Rectangle 0.9991612436631695\n"
     ]
    }
   ],
   "source": [
    "poly_reg_cercle = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_cercle.fit(split_train_cercle, split_target_train_cercle)\n",
    "poly_reg_cercle_creux = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_cercle_creux.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "poly_reg_rectangle_creux = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_rectangle_creux.fit(split_train_rectangle_creux, split_target_train_rectangle_creux)\n",
    "poly_reg_rectangle = PolynomialRegression(9, fit_intercept=True, normalize=True)\n",
    "poly_reg_rectangle.fit(split_train_rectangle, split_target_train_rectangle)\n",
    "\n",
    "Y_pred_cercle = poly_reg_cercle.predict(split_test_cercle)\n",
    "Y_pred_cercle_creux = poly_reg_cercle_creux.predict(split_test_cercle_creux)\n",
    "Y_pred_rectangle_creux = poly_reg_rectangle_creux.predict(split_test_rectangle_creux)\n",
    "Y_pred_rectangle = poly_reg_rectangle.predict(split_test_rectangle)\n",
    "\n",
    "# print score for each modèle\n",
    "print(\"Cercle : \",poly_reg_cercle.score(split_test_cercle, split_target_test_cercle))\n",
    "print(\"Cercle creux\",poly_reg_cercle_creux.score(split_test_cercle_creux, split_target_test_cercle_creux))\n",
    "print(\"Rectangle creuc\",poly_reg_rectangle_creux.score(split_test_rectangle_creux, split_target_test_rectangle_creux))\n",
    "print(\"Rectangle\",poly_reg_rectangle.score(split_test_rectangle, split_target_test_rectangle))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_tot</th>\n",
       "      <th>rho</th>\n",
       "      <th>h</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>0.477909</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.029576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27535</th>\n",
       "      <td>0.460209</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.021289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89717</th>\n",
       "      <td>0.920023</td>\n",
       "      <td>7800</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>0.048732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48235</th>\n",
       "      <td>0.451220</td>\n",
       "      <td>7850</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.025872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21381</th>\n",
       "      <td>0.984723</td>\n",
       "      <td>7850</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>0.055604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92054</th>\n",
       "      <td>0.441646</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.012825</td>\n",
       "      <td>0.031244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57135</th>\n",
       "      <td>0.763468</td>\n",
       "      <td>8900</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>0.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87646</th>\n",
       "      <td>0.629477</td>\n",
       "      <td>8900</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.036035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40190</th>\n",
       "      <td>0.226298</td>\n",
       "      <td>7850</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.009514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>0.245365</td>\n",
       "      <td>2700</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.020329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L_tot   rho         h         b\n",
       "13412  0.477909  2400  0.047055  0.029576\n",
       "27535  0.460209  2700  0.006365  0.021289\n",
       "89717  0.920023  7800  0.065778  0.048732\n",
       "48235  0.451220  7850  0.017114  0.025872\n",
       "21381  0.984723  7850  0.015821  0.055604\n",
       "92054  0.441646  2700  0.012825  0.031244\n",
       "57135  0.763468  8900  0.042613  0.068800\n",
       "87646  0.629477  8900  0.047380  0.036035\n",
       "40190  0.226298  7850  0.004465  0.009514\n",
       "7029   0.245365  2700  0.004439  0.020329"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train_rectangle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\Users\\enzoh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 19, 'n_estimators': 80}\n",
      "0.9378586418994692\n"
     ]
    }
   ],
   "source": [
    "# grid search for cercle_creux\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "\"\"\"my_grid_poly ={'polynomialfeatures__degree': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                'linearregression__fit_intercept': [True],\n",
    "                'linearregression__normalize': [True]}\n",
    "grid = GridSearchCV(PolynomialRegression(), my_grid_poly, cv=2,verbose=1)\n",
    "grid.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\"\"\"\n",
    "# best param degré = 6 true true for 0.97 best score \n",
    "\n",
    "my_grid_rf ={'n_estimators': [80],\n",
    "                'max_depth': [19,],\n",
    "                'min_samples_split': [2,3,4,5,6,7,8,9,10],\n",
    "              }\n",
    "                \n",
    "grid = GridSearchCV(RandomForestRegressor(), my_grid_rf, cv=2,verbose=1)\n",
    "grid.fit(split_train_cercle_creux, split_target_train_cercle_creux)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# plot prediction\\nplt.figure(figsize=(12, 5))\\nplt.plot((Y_pred_cercle)[:80])\\nplt.plot((np.array(split_target_test_cercle)[:80]))\\n\\nplt.legend(\\n    ['Y_grid_search', 'split_target_test'])\\nplt.show()\\n\\nplt.figure(figsize=(12, 5))\\nplt.plot((Y_pred_cercle_creux)[:80])\\nplt.plot((np.array(split_target_test_cercle_creux)[:80]))\\n\\nplt.legend(\\n    ['Y_grid_search', 'split_target_test'])\\nplt.show()\\n\\nplt.figure(figsize=(12, 5))\\nplt.plot((Y_pred_rectangle_creux)[:80])\\nplt.plot((np.array(split_target_test_rectangle_creux)[:80]))\\n\\nplt.legend(\\n    ['Y_grid_search', 'split_target_test'])\\nplt.show()\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# plot prediction\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_cercle)[:80])\n",
    "plt.plot((np.array(split_target_test_cercle)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_cercle_creux)[:80])\n",
    "plt.plot((np.array(split_target_test_cercle_creux)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot((Y_pred_rectangle_creux)[:80])\n",
    "plt.plot((np.array(split_target_test_rectangle_creux)[:80]))\n",
    "\n",
    "plt.legend(\n",
    "    ['Y_grid_search', 'split_target_test'])\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all 4 models with pickle\n",
    "with open('model_cercle.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_cercle, f)\n",
    "with open('model_cercle_creux.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_cercle_creux, f)\n",
    "with open('model_rectangle_creux.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_rectangle_creux, f)\n",
    "with open('model_rectangle.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_reg_rectangle, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91d527cafe2f425a4290ffff6183ccc7232b7b1c0c079161faf3c53f7523f56f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}